{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "484fb1cd-9bc1-4ce2-bc46-60c51f9ecc5c",
   "metadata": {},
   "source": [
    "üìì Notebook 6 ‚Äî Interactive Dashboard\n",
    "\n",
    "Purpose:\n",
    "Transition from static explainability (Notebook 5) to interactive, real-time exploration of model reasoning and training trends.\n",
    "The dashboard connects your PostgreSQL database, trained Random Forest models, and SHAP explainers into a transparent interface.\n",
    "\n",
    "üß≠ Overview\n",
    "\n",
    "Core Objectives\n",
    "Load models and processed run data from PostgreSQL\n",
    "Explore single-run predictions with SHAP explanations\n",
    "Compare two runs side-by-side (what changed?)\n",
    "View global feature importances and training trends\n",
    "\n",
    "Inputs\n",
    "models/random_forest_classifier.pkl\n",
    "models/shap_explainer_clf.pkl\n",
    "PostgreSQL table runs_summary\n",
    "\n",
    "Outputs\n",
    "Interactive Streamlit dashboard (06_dashboard_app.py)\n",
    "Visual insights into model reasoning and performance dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480cc506-5948-4cf9-9ab0-b01d2ee004d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# üß≠ Notebook 6 ‚Äî Interactive Dashboard\n",
    "# ===================================================\n",
    "# Purpose:\n",
    "# Move from static explainability (Notebook 5)\n",
    "# ‚Üí to *interactive exploration* and *real-time insights*.\n",
    "#\n",
    "# This notebook connects to PostgreSQL (Notebook 7),\n",
    "# loads trained models (Notebook 5),\n",
    "# and builds an interactive Streamlit dashboard\n",
    "# for local/global SHAP interpretation.\n",
    "# ===================================================\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# üì¶ 1. Setup & Imports\n",
    "# ---------------------------------------------------\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# ‚úÖ FIXED: Ensure the project root is correctly resolved\n",
    "# This finds the \"running-agent\" folder even when Streamlit runs from a parent dir.\n",
    "project_root = Path(__file__).resolve().parents[1]\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "print(\"‚úÖ Project root added to path:\", project_root)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# üîß Robust project root detection\n",
    "# ---------------------------------------------------\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def _find_project_root() -> Path:\n",
    "    \"\"\"\n",
    "    Walk up from __file__ and CWD to find a directory that\n",
    "    contains both 'models' and 'src'. Falls back to the folder\n",
    "    named 'running-agent' if found by name.\n",
    "    \"\"\"\n",
    "    candidates = [Path(__file__).resolve(), Path.cwd().resolve()]\n",
    "    seen = set()\n",
    "\n",
    "    for base in candidates:\n",
    "        for p in [base] + list(base.parents):\n",
    "            if p in seen:\n",
    "                continue\n",
    "            seen.add(p)\n",
    "            if (p / \"models\").exists() and (p / \"src\").exists():\n",
    "                return p\n",
    "\n",
    "    # Fallback: choose the directory named 'running-agent' if present\n",
    "    for p in [Path(__file__).resolve()] + list(Path(__file__).resolve().parents):\n",
    "        if p.name.lower() == \"running-agent\":\n",
    "            return p\n",
    "\n",
    "    # Last resort: one level up from this file\n",
    "    return Path(__file__).resolve().parents[1]\n",
    "\n",
    "project_root = _find_project_root()\n",
    "sys.path.append(str(project_root))\n",
    "print(\"‚úÖ Project root resolved to:\", project_root)\n",
    "\n",
    "# Paths that depend on the root\n",
    "model_dir = project_root / \"models\"\n",
    "rf_model_path = model_dir / \"random_forest_classifier.pkl\"\n",
    "explainer_path = model_dir / \"shap_explainer_clf.pkl\"\n",
    "\n",
    "print(\"üìÇ Model directory:\", model_dir)\n",
    "print(\" - Classifier exists:\", rf_model_path.exists(), \"‚Üí\", rf_model_path)\n",
    "print(\" - SHAP explainer exists:\", explainer_path.exists(), \"‚Üí\", explainer_path)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# üîç Standard Libraries\n",
    "# ---------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import shap\n",
    "import streamlit as st\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# üß© Custom Project Imports\n",
    "# ---------------------------------------------------\n",
    "from src.db_utils import get_engine\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# ‚öôÔ∏è Streamlit Setup (safe to ignore warnings in Jupyter)\n",
    "# ---------------------------------------------------\n",
    "try:\n",
    "    st.set_page_config(page_title=\"üèÉ‚Äç‚ôÇÔ∏è Running Insights Dashboard\", layout=\"wide\")\n",
    "except Exception:\n",
    "    print(\"‚ö†Ô∏è Streamlit context not active (OK in Jupyter)\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# üìÅ Define Model Paths\n",
    "# ---------------------------------------------------\n",
    "model_dir = project_root / \"models\"\n",
    "rf_model_path = model_dir / \"random_forest_classifier.pkl\"\n",
    "explainer_path = model_dir / \"shap_explainer_clf.pkl\"\n",
    "\n",
    "print(\"üìÇ Model directory:\", model_dir)\n",
    "print(\" - Classifier exists:\", rf_model_path.exists())\n",
    "print(\" - SHAP explainer exists:\", explainer_path.exists())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c8e563-6d3d-477f-aba8-7f7516d23aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# üß† 2. Load Models and Data (PostgreSQL + Pickles)\n",
    "# ---------------------------------------------------\n",
    "@st.cache_resource\n",
    "def load_models():\n",
    "    \"\"\"Load trained model and SHAP explainer.\"\"\"\n",
    "    rf_clf = joblib.load(rf_model_path)\n",
    "    try:\n",
    "        explainer_clf = joblib.load(explainer_path)\n",
    "        print(\"‚úÖ Models and explainer loaded successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        explainer_clf = None\n",
    "        print(\"‚ö†Ô∏è No SHAP explainer found ‚Äì plots will be skipped.\")\n",
    "    return rf_clf, explainer_clf\n",
    "\n",
    "\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    \"\"\"Read processed runs from PostgreSQL.\"\"\"\n",
    "    engine = get_engine()\n",
    "    df = pd.read_sql(\"SELECT * FROM runs_summary ORDER BY date DESC\", engine)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "rf_clf, explainer_clf = load_models()\n",
    "summary_df = load_data()\n",
    "\n",
    "print(\"‚úÖ Models and data loaded ‚Äî ready for dashboard.\")\n",
    "print(\"Data shape:\", summary_df.shape)\n",
    "summary_df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f0c6ce-c187-4a2f-815d-168b81c668fc",
   "metadata": {},
   "source": [
    "| Feature             | Description                   |\n",
    "| ------------------- | ----------------------------- |\n",
    "| `total_distance_km` | Distance of run in km         |\n",
    "| `duration_min`      | Duration in minutes           |\n",
    "| `avg_pace_min_km`   | Average pace (min/km)         |\n",
    "| `avg_cadence`       | Steps per minute              |\n",
    "| `total_elev_gain`   | Elevation gain (m)            |\n",
    "| `avg_stride_len_m`  | Average stride length (m)     |\n",
    "| `avg_gct_est_ms`    | Ground contact time (ms)      |\n",
    "| `pace_variability`  | Pace consistency index        |\n",
    "| `cadence_drift`     | Cadence stability index       |\n",
    "| `load_7d`           | 7-day rolling training load   |\n",
    "| `load_28d`          | 28-day rolling training load  |\n",
    "| `fastest_1km_pace`  | Fastest 1 km segment (min/km) |\n",
    "| `fastest_5min_pace` | Fastest 5 min pace (min/km)   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8381b5f-f774-4e50-b404-9086674ce83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_features = [\n",
    "    \"total_distance_km\",\"duration_min\",\"avg_pace_min_km\",\"avg_cadence\",\n",
    "    \"total_elev_gain\",\"avg_stride_len_m\",\"avg_gct_est_ms\",\n",
    "    \"pace_variability\",\"cadence_drift\",\"load_7d\",\"load_28d\",\n",
    "    \"fastest_1km_pace\",\"fastest_5min_pace\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4c0f2f-e7bc-43a2-8a20-c3335d9b38e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def shap_vector_for_sample(explainer, model, X_one_row: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Return a 1-D SHAP vector for the predicted class and the raw array for debugging.\n",
    "    Handles shapes like (1, n_features, n_classes) or (1, n_classes, n_features).\n",
    "    \"\"\"\n",
    "    assert X_one_row.shape[0] == 1, \"Pass exactly one sample\"\n",
    "\n",
    "    nfeat = X_one_row.shape[1]\n",
    "    cols = list(X_one_row.columns)\n",
    "    try:\n",
    "        c = int(np.argmax(model.predict_proba(X_one_row), axis=1)[0])\n",
    "    except Exception:\n",
    "        c = 0\n",
    "\n",
    "    raw = explainer.shap_values(X_one_row)\n",
    "    arr = np.asarray(raw)\n",
    "\n",
    "    if isinstance(raw, list):\n",
    "        v = np.array(raw[c]).reshape(-1)\n",
    "        if v.shape[0] == nfeat: return v, raw\n",
    "        elif v.ndim > 1 and v.shape[1] == nfeat: return v[0], raw\n",
    "        else: raise ValueError(f\"List SHAP shape {v.shape}\")\n",
    "    elif arr.ndim == 3 and arr.shape[1] == nfeat:\n",
    "        v = arr[0, :, c]\n",
    "    elif arr.ndim == 3 and arr.shape[2] == nfeat:\n",
    "        v = arr[0, c, :]\n",
    "    elif arr.ndim == 2 and arr.shape == (1, nfeat):\n",
    "        v = arr[0, :]\n",
    "    elif arr.ndim == 1 and arr.shape[0] == nfeat:\n",
    "        v = arr\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected SHAP shape {arr.shape}\")\n",
    "    return v, raw\n",
    "\n",
    "print(\"‚úÖ SHAP vector helper ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7b9797-63dc-4bcc-9c03-076dac369931",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.title(\"üèÉ‚Äç‚ôÇÔ∏è Running Insights Dashboard\")\n",
    "st.markdown(\"\"\"\n",
    "Explore your running data and model reasoning interactively.  \n",
    "Tabs:\n",
    "1Ô∏è‚É£ Inspect a single run prediction  \n",
    "2Ô∏è‚É£ Compare two runs side-by-side  \n",
    "3Ô∏è‚É£ Explore global feature importance and performance trends\n",
    "\"\"\")\n",
    "\n",
    "tab1, tab2, tab3 = st.tabs([\"üîç Single Run\",\"üìà Compare Runs\",\"üåç Global Insights\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4445553a-7c41-466e-8db7-8de7ad7402d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tab1:\n",
    "    st.subheader(\"Single Run SHAP Explanation\")\n",
    "    options = summary_df[\"date\"].dt.strftime(\"%Y-%m-%d\").tolist()\n",
    "    selected_date = st.selectbox(\"Select a run date\", options)\n",
    "    case = summary_df[summary_df[\"date\"].dt.strftime(\"%Y-%m-%d\") == selected_date]\n",
    "\n",
    "    if case.empty:\n",
    "        st.warning(\"No data for selected date.\")\n",
    "    else:\n",
    "        X_means = summary_df[available_features].mean()\n",
    "        case_X = case[available_features].fillna(X_means).iloc[[0]]\n",
    "        pred_label = rf_clf.predict(case_X)[0]\n",
    "        st.markdown(f\"### üè∑Ô∏è Predicted Cluster: **{pred_label}**\")\n",
    "\n",
    "        if explainer_clf is None:\n",
    "            st.info(\"SHAP explainer missing ‚Äî skip plot.\")\n",
    "        else:\n",
    "            shap_vec, _ = shap_vector_for_sample(explainer_clf, rf_clf, case_X)\n",
    "            contrib = pd.Series(shap_vec, index=case_X.columns).sort_values(key=lambda x: x.abs(), ascending=False)\n",
    "            st.bar_chart(contrib.head(10))\n",
    "            st.caption(\"Top 10 SHAP feature contributions for selected run.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efb2e58-b589-4f36-8dcc-27fa6749b6f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf6a4ce-2a56-4d11-8828-f104c92af632",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tab2:\n",
    "    st.subheader(\"Compare Two Runs (SHAP Difference)\")\n",
    "\n",
    "    dates = summary_df[\"date\"].dt.strftime(\"%Y-%m-%d\").tolist()\n",
    "    col1, col2 = st.columns(2)\n",
    "    d1 = col1.selectbox(\"Run 1 date\", dates, index=0)\n",
    "    d2 = col2.selectbox(\"Run 2 date\", dates, index=1)\n",
    "\n",
    "    df1 = summary_df[summary_df[\"date\"].dt.strftime(\"%Y-%m-%d\") == d1]\n",
    "    df2 = summary_df[summary_df[\"date\"].dt.strftime(\"%Y-%m-%d\") == d2]\n",
    "\n",
    "    if explainer_clf and (not df1.empty and not df2.empty):\n",
    "        shap1, _ = shap_vector_for_sample(explainer_clf, rf_clf, df1[available_features])\n",
    "        shap2, _ = shap_vector_for_sample(explainer_clf, rf_clf, df2[available_features])\n",
    "        diff = pd.Series(shap2 - shap1, index=available_features).sort_values(key=lambda x: x.abs(), ascending=False)\n",
    "        st.bar_chart(diff.head(10))\n",
    "        st.caption(\"Difference in SHAP contributions between two runs.\")\n",
    "    else:\n",
    "        st.warning(\"Ensure both runs and explainer are available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0f3041-d199-49be-ad2e-46a42d6b49d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tab3:\n",
    "    st.subheader(\"Global Feature Importance and Trends\")\n",
    "\n",
    "    if explainer_clf:\n",
    "        shap_values = explainer_clf.shap_values(summary_df[available_features])\n",
    "        mean_abs = np.mean(np.abs(np.array(shap_values)), axis=(0, 1))\n",
    "        global_df = pd.DataFrame({\"feature\": available_features, \"importance\": mean_abs})\n",
    "        global_df = global_df.sort_values(\"importance\", ascending=False)\n",
    "\n",
    "        chart = alt.Chart(global_df.head(10)).mark_bar().encode(\n",
    "            x=alt.X(\"importance:Q\", title=\"Mean |SHAP|\"),\n",
    "            y=alt.Y(\"feature:N\", sort=\"-x\", title=\"Feature\")\n",
    "        )\n",
    "        st.altair_chart(chart, use_container_width=True)\n",
    "        st.caption(\"Mean absolute SHAP importance across all runs.\")\n",
    "\n",
    "    st.markdown(\"#### Performance trends over time\")\n",
    "    trend = alt.Chart(summary_df).mark_line(point=True).encode(\n",
    "        x=\"date:T\", y=\"avg_pace_min_km:Q\", color=alt.value(\"#007AFF\")\n",
    "    )\n",
    "    st.altair_chart(trend, use_container_width=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4758ed-7039-4d93-afba-6ed24a0288bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147aa4f0-0fbe-4914-8e09-a2f475c8b55c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade3409b-a842-4518-bff4-17989e3d5d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e46cdf-88cf-40c3-a108-23eaa1f75a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3596da26-c930-44a9-bbf9-614b2a15944b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
