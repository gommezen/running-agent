# ğŸƒ Running Agent â€” Data Science Project

This project analyzes running data (Garmin/Strava `.fit` files) to extract insights, track training load, and build predictive models.  
It serves both as a **personal training analytics tool** and a **data-science portfolio project** demonstrating reproducible pipelines, explainable ML, and SQL database integration.

---

## ğŸ“Š Overview

**Purpose**
- Understand and visualize running patterns  
- Track progress (distance, pace, cadence, training load)  
- Cluster runs into natural types (easy, tempo, intervals, hilly)  
- Build predictive models for pace and fatigue  
- Prototype a â€œTamagotchi-styleâ€ agent that suggests training intensity

---

## ğŸ““ Notebook Workflow

| Notebook | Focus | Key Outputs |
|-----------|--------|-------------|
| **01_explore_data** | Load & explore Garmin/Strava data | Basic stats & visualizations |
| **02_feature_engineering** | Compute derived features (load, variability, cadence drift) | `runs_summary.csv` |
| **03_clustering_runs** | Group runs by training type using unsupervised learning | Cluster labels |
| **04_predictive_models** | Random Forest regression & classification | Pace & cluster predictions |
| **05_model_interpretation** | SHAP explainability | Global + local feature contributions |
| **06_interactive_dashboard** *(next)* | Streamlit app for prediction & explainability | Live UI |
| **07_postgresql_storage** | Persist processed data & SHAP summaries to PostgreSQL | Tables: `runs_summary`, `shap_importance_global`, `data_lineage` |

---

## ğŸ—„ï¸ Database Integration

- **PostgreSQL 16** is used for structured, secure data storage  
- **SQLAlchemy** handles database connections and read/write operations  
- Created tables:
  - `runs_summary` â†’ per-run features and training stats  
  - `shap_importance_global` â†’ mean SHAP feature importances  
  - `data_lineage` â†’ dataset version and timestamp logs
- Includes validation queries for:
  - Weekly statistics  
  - Top-importance SHAP features  
  - Metadata logging for reproducibility  

---

## ğŸ§± Folder Structure

running-agent/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # ignored
â”‚ â”œâ”€â”€ interim/ # ignored
â”‚ â”œâ”€â”€ processed/ # local only (ignored in Git)
â”‚ â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ 01_explore_data.ipynb
â”‚ â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚ â”œâ”€â”€ 03_clustering_runs.ipynb
â”‚ â”œâ”€â”€ 04_predictive_models.ipynb
â”‚ â”œâ”€â”€ 05_model_interpretation.ipynb
â”‚ â”œâ”€â”€ 06_interactive_dashboard.ipynb
â”‚ â””â”€â”€ 07_postgresql_storage.ipynb
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ init.py
â”‚ â””â”€â”€ db_utils.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ check_storage.sql


---

## âš™ï¸ Environment Setup

```bash
# Clone the repository
git clone https://github.com/<YOUR_USERNAME>/running-agent.git
cd running-agent

# Create environment and install dependencies
python -m venv .venv
.\.venv\Scripts\activate
pip install -r requirements.txt

# Test database connection
python -m src.db_utils


ğŸ§© Next Steps for this project

1. Notebook 6 â†’ Build Streamlit dashboard for live predictions
2. Notebook 8 â†’ Add monitoring and automatic database logging
3. Dockerize the app for portable deployment
4. Enable GitHub Actions for CI/CD checks
5. Integrate Garmin/Strava API for automated data ingestion

ğŸªª License

MIT License Â© 2025 Niels JÃ¸rgen Gommesen